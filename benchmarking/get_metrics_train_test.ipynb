{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Benchmarking Pipeline with Excel Export\n",
    "\n",
    "This notebook provides a complete workflow for:\n",
    "1. Running comprehensive benchmarks across multiple models and datasets\n",
    "2. Generating standardized summary files\n",
    "3. Creating formatted Excel reports with performance rankings\n",
    "\n",
    "**Models included:**\n",
    "- **AbLang Family**: AbLangPDB, AbLangRBD, AbLangPre, AbLang2, AbLang-Heavy (cosine similarity)\n",
    "- **Other Protein LMs**: AntiBERTy, BALM, ESM-2, IgBERT, Parapred (cosine similarity)\n",
    "- **Structure-based**: ABodyBuilder2 (Dynamic Time Warping over CDRs $e^{-(DTW/2)^2}$) \n",
    "- **Sequence-based**: SEQID (sequence identity), CDRH3ID (CDRH3 identity)\n",
    "\n",
    "**Datasets:**\n",
    "- SAbDab (structural antibody database)\n",
    "- DMS (deep mutational scanning)\n",
    "\n",
    "**Features:**\n",
    "- Works with ALL available parquet files in the benchmarking directory\n",
    "- Optional embedding re-calculation toggle (disabled by default)\n",
    "- Optional threshold reuse for faster re-runs\n",
    "- Comprehensive error handling and logging\n",
    "- Supports up to 12+ different models across both datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  â€¢ Recalculate embeddings: False\n",
      "  â€¢ Recalculate summary metrics: False\n",
      "  â€¢ Output folder: output_csvs\n",
      "  â€¢ Excel filename: comprehensive_benchmarking_results.xlsx\n",
      "  â€¢ Batch size: 256\n",
      "\n",
      "ðŸ“ Note: This notebook now supports ALL available parquet files:\n",
      "  â€¢ Models: AbLangPDB, AbLangRBD, AbLangPre, AbLang2, AbLang-Heavy,\n",
      "           AntiBERTy, BALM, ESM-2, IgBERT, Parapred, SEQID, CDRH3ID,\n",
      "           ABodyBuilder2_DTW_CDRs\n",
      "  â€¢ Datasets: SAbDab and DMS\n",
      "  â€¢ Only existing parquet files will be processed\n",
      "  â€¢ Summary metrics will be reused if available\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION FLAGS - MODIFY THESE AS NEEDED\n",
    "# =============================================================================\n",
    "\n",
    "# Set to False to use existing parquet files (faster), True to re-calculate embeddings\n",
    "# NOTE: This notebook now works with ALL available parquet files in the directory\n",
    "RECALCULATE_EMBEDDINGS = False\n",
    "\n",
    "# Set to False to skip benchmark recalculation if summary files exist (faster), True to always recalculate\n",
    "RECALCULATE_SUMMARYMETRICS = False\n",
    "\n",
    "# Model paths - update these paths as needed\n",
    "MODEL_PATHS = {\n",
    "    \"AbLangPDB\": \"../../../huggingface/AbLangPDB1/ablangpdb_model.safetensors\",\n",
    "    \"AbLangRBD\": \"../../../huggingface/AbLangRBD1/model.safetensors\"\n",
    "}\n",
    "\n",
    "# Batch size for embedding generation\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Output configuration\n",
    "OUTPUT_FOLDER = \"output_csvs\"\n",
    "EXCEL_FILENAME = \"comprehensive_benchmarking_results.xlsx\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  â€¢ Recalculate embeddings: {RECALCULATE_EMBEDDINGS}\")\n",
    "print(f\"  â€¢ Recalculate summary metrics: {RECALCULATE_SUMMARYMETRICS}\")\n",
    "print(f\"  â€¢ Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"  â€¢ Excel filename: {EXCEL_FILENAME}\")\n",
    "print(f\"  â€¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\\nðŸ“ Note: This notebook now supports ALL available parquet files:\")\n",
    "print(f\"  â€¢ Models: AbLangPDB, AbLangRBD, AbLangPre, AbLang2, AbLang-Heavy,\")\n",
    "print(f\"           AntiBERTy, BALM, ESM-2, IgBERT, Parapred, SEQID, CDRH3ID,\")\n",
    "print(f\"           ABodyBuilder2_DTW_CDRs\")\n",
    "print(f\"  â€¢ Datasets: SAbDab and DMS\")\n",
    "print(f\"  â€¢ Only existing parquet files will be processed\")\n",
    "print(f\"  â€¢ Summary metrics will be {'recalculated' if RECALCULATE_SUMMARYMETRICS else 'reused if available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import typing as T\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import local modules\n",
    "import calculate_metrics\n",
    "import calculate_metrics_dms\n",
    "import models\n",
    "from excel_generator import generate_results_excel, print_summary_stats\n",
    "from ablangpaired_model import AbLangPairedConfig, AbLangPaired\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_file_exists(filepath, description=\"\"):\n",
    "    \"\"\"Check if a file exists and return status.\"\"\"\n",
    "    exists = os.path.exists(filepath)\n",
    "    status = \"âœ…\" if exists else \"âŒ\"\n",
    "    print(f\"  {status} {description}: {filepath}\")\n",
    "    return exists\n",
    "\n",
    "\n",
    "def embed_with_ablangpaired(input_path: str, output_path: str, model_path: str, model_name: str):\n",
    "    \"\"\"Generate embeddings using AbLangPaired models.\n",
    "    \n",
    "        Args:\n",
    "            model_name: str. If \"ablangpre\" then the model architecture will no longer have the mixer layer.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ”„ Generating {model_name} embeddings...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_parquet(input_path)\n",
    "    if \"EMBEDDING\" in df.columns:\n",
    "        df = df.drop(columns=[\"EMBEDDING\"])\n",
    "    \n",
    "    # Setup model\n",
    "    model_config = AbLangPairedConfig(checkpoint_filename=model_path)\n",
    "    is_ablangpre = model_name == \"ablangpre\"\n",
    "    model = AbLangPaired(model_config, device=device, use_pretrained=is_ablangpre)\n",
    "    \n",
    "    # Tokenize and embed using enhanced methods\n",
    "    tokenized_dataloader = models.tokenize_data(df, model_config, batch_size=BATCH_SIZE)\n",
    "    all_embeds = models.embed_dataloader(tokenized_dataloader, model, device)\n",
    "    \n",
    "    # Save\n",
    "    df['EMBEDDING'] = list(all_embeds.cpu().numpy())\n",
    "    df.to_parquet(output_path)\n",
    "    \n",
    "    print(f\"âœ… {model_name} embeddings saved to {output_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_summary_file_paths(model_name: str, dataset_type: str, output_folder: str):\n",
    "    \"\"\"Get expected summary file paths for a model/dataset combination.\"\"\"\n",
    "    if dataset_type == \"sabdab\":\n",
    "        # SAbDab has both epitope and antigen summary files\n",
    "        epitope_file = os.path.join(output_folder, f\"{model_name}_sabdab_ep_summarymetrics.txt\")\n",
    "        antigen_file = os.path.join(output_folder, f\"{model_name}_sabdab_ag_summarymetrics.txt\")\n",
    "        return [epitope_file, antigen_file]\n",
    "    elif dataset_type == \"dms\":\n",
    "        # DMS has only one summary file\n",
    "        dms_file = os.path.join(output_folder, f\"{model_name}_dms_summarymetrics.txt\")\n",
    "        return [dms_file]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def read_and_display_summary_results(summary_files: list, model_name: str, dataset_type: str):\n",
    "    \"\"\"Read and display results from existing summary files.\"\"\"\n",
    "    print(f\"\\nðŸ“Š Loading existing results for {model_name} on {dataset_type}:\")\n",
    "    \n",
    "    for summary_file in summary_files:\n",
    "        if os.path.exists(summary_file):\n",
    "            try:\n",
    "                with open(summary_file, 'r') as f:\n",
    "                    content = f.read().strip()\n",
    "                \n",
    "                # Extract the task type from filename\n",
    "                if \"sabdab_ep\" in summary_file:\n",
    "                    task_type = \"Epitope-level performance\"\n",
    "                elif \"sabdab_ag\" in summary_file:\n",
    "                    task_type = \"Antigen-level performance\"\n",
    "                else:\n",
    "                    task_type = \"Performance\"\n",
    "                \n",
    "                print(f\"\\n--- {task_type} ---\")\n",
    "                print(content)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error reading {summary_file}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ Summary file not found: {summary_file}\")\n",
    "\n",
    "\n",
    "print(\"Helper functions loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Embedding Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Required Base Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Checking base dataset files...\n",
      "  âœ… SAbDab base dataset: ablangpdb_renameddatasets.parquet\n",
      "  âœ… DMS base dataset: ablangrbd_renameddatasets.parquet\n",
      "  âœ… SAbDab validation labels: ablangpdb_train_val_label_mat.pt\n",
      "  âœ… SAbDab test labels: ablangpdb_train_test_label_mat.pt\n",
      "  âœ… DMS validation labels: dms_train_val_label_mat.pt\n",
      "  âœ… DMS test labels: dms_train_test_label_mat.pt\n",
      "\n",
      "âœ… All base files found!\n"
     ]
    }
   ],
   "source": [
    "# Check that base dataset files exist\n",
    "print(\"ðŸ“‹ Checking base dataset files...\")\n",
    "\n",
    "base_files = {\n",
    "    \"SAbDab base dataset\": \"ablangpdb_renameddatasets.parquet\",\n",
    "    \"DMS base dataset\": \"ablangrbd_renameddatasets.parquet\",\n",
    "    \"SAbDab validation labels\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "    \"SAbDab test labels\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "    \"DMS validation labels\": \"dms_train_val_label_mat.pt\",\n",
    "    \"DMS test labels\": \"dms_train_test_label_mat.pt\"\n",
    "}\n",
    "\n",
    "missing_base_files = []\n",
    "for desc, filepath in base_files.items():\n",
    "    if not check_file_exists(filepath, desc):\n",
    "        missing_base_files.append(filepath)\n",
    "\n",
    "if missing_base_files:\n",
    "    raise FileNotFoundError(f\"Missing required base files: {missing_base_files}\")\n",
    "\n",
    "print(\"\\nâœ… All base files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EMBEDDING FILE STATUS CHECK\n",
      "============================================================\n",
      " Checking for existing embedding files (no regeneration)...\n",
      "âœ… Found: sabdab_embeddedby_ablangrbd.parquet\n",
      "âœ… Found: sabdab_embeddedby_ablangpre.parquet\n",
      "âœ… Found: sabdab_embeddedby_ablang2.parquet\n",
      "âœ… Found: sabdab_embeddedby_ablang-heavy.parquet\n",
      "âœ… Found: sabdab_embeddedby_antiberty.parquet\n",
      "âœ… Found: sabdab_embeddedby_balm.parquet\n",
      "âœ… Found: sabdab_embeddedby_esm-2.parquet\n",
      "âœ… Found: sabdab_embeddedby_igbert.parquet\n",
      "âœ… Found: sabdab_embeddedby_parapred.parquet\n",
      "âœ… Found: dms_embeddedby_ablangpdb.parquet\n",
      "âœ… Found: dms_embeddedby_ablangpre.parquet\n",
      "âœ… Found: dms_embeddedby_ablang2.parquet\n",
      "âœ… Found: dms_embeddedby_ablang-heavy.parquet\n",
      "âœ… Found: dms_embeddedby_antiberty.parquet\n",
      "âœ… Found: dms_embeddedby_balm.parquet\n",
      "âœ… Found: dms_embeddedby_esm-2.parquet\n",
      "âœ… Found: dms_embeddedby_igbert.parquet\n",
      "âœ… Found: dms_embeddedby_parapred.parquet\n",
      "\n",
      "ðŸ“Š Embedding Files Summary:\n",
      "  â€¢ Existing files: 18/18\n",
      "  â€¢ Missing files: 0\n",
      "\n",
      "âœ… Embedding file check complete!\n"
     ]
    }
   ],
   "source": [
    "# Define all embedding files that should exist\n",
    "embedding_files = {\n",
    "    # SAbDab dataset embeddings\n",
    "    \"sabdab_embeddedby_ablangrbd.parquet\": (\"ablangpdb_renameddatasets.parquet\", MODEL_PATHS.get(\"AbLangRBD\"), \"AbLangRBD\"),\n",
    "    \"sabdab_embeddedby_ablangpre.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"AbLangPre\"),\n",
    "    \"sabdab_embeddedby_ablang2.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"AbLang2\"),\n",
    "    \"sabdab_embeddedby_ablang-heavy.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"AbLang-Heavy\"),\n",
    "    \"sabdab_embeddedby_antiberty.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"AntiBERTy\"),\n",
    "    \"sabdab_embeddedby_balm.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"BALM\"),\n",
    "    \"sabdab_embeddedby_esm-2.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"ESM-2\"),\n",
    "    \"sabdab_embeddedby_igbert.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"IgBERT\"),\n",
    "    \"sabdab_embeddedby_parapred.parquet\": (\"ablangpdb_renameddatasets.parquet\", None, \"Parapred\"),\n",
    "\n",
    "    # DMS dataset embeddings\n",
    "    \"dms_embeddedby_ablangpdb.parquet\": (\"ablangrbd_renameddatasets.parquet\", MODEL_PATHS.get(\"AbLangPDB\"), \"AbLangPDB\"),\n",
    "    \"dms_embeddedby_ablangpre.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"AbLangPre\"),\n",
    "    \"dms_embeddedby_ablang2.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"AbLang2\"),\n",
    "    \"dms_embeddedby_ablang-heavy.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"AbLang-Heavy\"),\n",
    "    \"dms_embeddedby_antiberty.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"AntiBERTy\"),\n",
    "    \"dms_embeddedby_balm.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"BALM\"),\n",
    "    \"dms_embeddedby_esm-2.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"ESM-2\"),\n",
    "    \"dms_embeddedby_igbert.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"IgBERT\"),\n",
    "    \"dms_embeddedby_parapred.parquet\": (\"ablangrbd_renameddatasets.parquet\", None, \"Parapred\")\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EMBEDDING FILE STATUS CHECK\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(\" Checking for existing embedding files (no regeneration)...\")\n",
    "\n",
    "existing_files = []\n",
    "missing_files = []\n",
    "\n",
    "for output_file, (input_file, model_path, model_name) in embedding_files.items():\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"âœ… Found: {output_file}\")\n",
    "        existing_files.append(output_file)\n",
    "    else:\n",
    "        print(f\"âŒ Missing: {output_file}\")\n",
    "        missing_files.append(output_file)\n",
    "\n",
    "print(f\"\\nðŸ“Š Embedding Files Summary:\")\n",
    "print(f\"  â€¢ Existing files: {len(existing_files)}/{len(embedding_files)}\")\n",
    "print(f\"  â€¢ Missing files: {len(missing_files)}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nâš ï¸ Missing embedding files:\")\n",
    "    for file in missing_files:\n",
    "        print(f\"  - {file}\")\n",
    "    print(\"\\nNote: Configurations using missing files will be skipped automatically.\")\n",
    "\n",
    "print(f\"\\nâœ… Embedding file check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify All Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Verifying all required files...\n",
      "  âœ… SAbDab base (AbLangPDB embeddings): ablangpdb_renameddatasets.parquet\n",
      "  âœ… DMS base: ablangrbd_renameddatasets.parquet\n",
      "  âœ… SAbDab + AbLangRBD: sabdab_embeddedby_ablangrbd.parquet\n",
      "  âœ… SAbDab + AbLangPre: sabdab_embeddedby_ablangpre.parquet\n",
      "  âœ… SAbDab + AbLang2: sabdab_embeddedby_ablang2.parquet\n",
      "  âœ… SAbDab + AbLang-Heavy: sabdab_embeddedby_ablang-heavy.parquet\n",
      "  âœ… SAbDab + AntiBERTy: sabdab_embeddedby_antiberty.parquet\n",
      "  âœ… SAbDab + BALM: sabdab_embeddedby_balm.parquet\n",
      "  âœ… SAbDab + ESM-2: sabdab_embeddedby_esm-2.parquet\n",
      "  âœ… SAbDab + IgBERT: sabdab_embeddedby_igbert.parquet\n",
      "  âœ… SAbDab + Parapred: sabdab_embeddedby_parapred.parquet\n",
      "  âœ… DMS + AbLangPDB: dms_embeddedby_ablangpdb.parquet\n",
      "  âœ… DMS + AbLangPre: dms_embeddedby_ablangpre.parquet\n",
      "  âœ… DMS + AbLang2: dms_embeddedby_ablang2.parquet\n",
      "  âœ… DMS + AbLang-Heavy: dms_embeddedby_ablang-heavy.parquet\n",
      "  âœ… DMS + AntiBERTy: dms_embeddedby_antiberty.parquet\n",
      "  âœ… DMS + BALM: dms_embeddedby_balm.parquet\n",
      "  âœ… DMS + ESM-2: dms_embeddedby_esm-2.parquet\n",
      "  âœ… DMS + IgBERT: dms_embeddedby_igbert.parquet\n",
      "  âœ… DMS + Parapred: dms_embeddedby_parapred.parquet\n",
      "  âœ… SAbDab validation labels: ablangpdb_train_val_label_mat.pt\n",
      "  âœ… SAbDab test labels: ablangpdb_train_test_label_mat.pt\n",
      "  âœ… DMS validation labels: dms_train_val_label_mat.pt\n",
      "  âœ… DMS test labels: dms_train_test_label_mat.pt\n",
      "\n",
      "âœ… All required files are available!\n"
     ]
    }
   ],
   "source": [
    "# Check that all required files now exist\n",
    "print(\"\\nðŸ“‹ Verifying all required files...\")\n",
    "\n",
    "all_required_files = {\n",
    "    # Base datasets\n",
    "    \"SAbDab base (AbLangPDB embeddings)\": \"ablangpdb_renameddatasets.parquet\",\n",
    "    \"DMS base\": \"ablangrbd_renameddatasets.parquet\",\n",
    "    \n",
    "    # SAbDab embedding files\n",
    "    \"SAbDab + AbLangRBD\": \"sabdab_embeddedby_ablangrbd.parquet\",\n",
    "    \"SAbDab + AbLangPre\": \"sabdab_embeddedby_ablangpre.parquet\",\n",
    "    \"SAbDab + AbLang2\": \"sabdab_embeddedby_ablang2.parquet\",\n",
    "    \"SAbDab + AbLang-Heavy\": \"sabdab_embeddedby_ablang-heavy.parquet\",\n",
    "    \"SAbDab + AntiBERTy\": \"sabdab_embeddedby_antiberty.parquet\",\n",
    "    \"SAbDab + BALM\": \"sabdab_embeddedby_balm.parquet\",\n",
    "    \"SAbDab + ESM-2\": \"sabdab_embeddedby_esm-2.parquet\",\n",
    "    \"SAbDab + IgBERT\": \"sabdab_embeddedby_igbert.parquet\",\n",
    "    \"SAbDab + Parapred\": \"sabdab_embeddedby_parapred.parquet\",\n",
    "    \n",
    "    # DMS embedding files\n",
    "    \"DMS + AbLangPDB\": \"dms_embeddedby_ablangpdb.parquet\",\n",
    "    \"DMS + AbLangPre\": \"dms_embeddedby_ablangpre.parquet\",\n",
    "    \"DMS + AbLang2\": \"dms_embeddedby_ablang2.parquet\",\n",
    "    \"DMS + AbLang-Heavy\": \"dms_embeddedby_ablang-heavy.parquet\",\n",
    "    \"DMS + AntiBERTy\": \"dms_embeddedby_antiberty.parquet\",\n",
    "    \"DMS + BALM\": \"dms_embeddedby_balm.parquet\",\n",
    "    \"DMS + ESM-2\": \"dms_embeddedby_esm-2.parquet\",\n",
    "    \"DMS + IgBERT\": \"dms_embeddedby_igbert.parquet\",\n",
    "    \"DMS + Parapred\": \"dms_embeddedby_parapred.parquet\",\n",
    "\n",
    "    # ABodyBuilder2 DTW Pre-computed results\n",
    "    \"SAbDab + ABodyBuilder2 (for thresholding)\": \"sabdab_pairwise_cdr_sims_train_vs_val.npy\",\n",
    "    \"SAbDab + ABodyBuilder2\": \"sabdab_pairwise_cdr_sims_train_vs_test.npy\",\n",
    "    \"DMS + ABodyBuilder2 (for thresholding)\": \"dms_pairwise_cdr_sims_train_vs_val.npy\",\n",
    "    \"DMS + ABodyBuilder2\": \"dms_pairwise_cdr_sims_train_vs_test.npy\",\n",
    "    \n",
    "    # Label matrices\n",
    "    \"SAbDab validation labels\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "    \"SAbDab test labels\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "    \"DMS validation labels\": \"dms_train_val_label_mat.pt\",\n",
    "    \"DMS test labels\": \"dms_train_test_label_mat.pt\"\n",
    "}\n",
    "\n",
    "missing_files = []\n",
    "for desc, filepath in all_required_files.items():\n",
    "    if not check_file_exists(filepath, desc):\n",
    "        missing_files.append(filepath)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nâš ï¸ Warning: {len(missing_files)} files are missing:\")\n",
    "    for file in missing_files:\n",
    "        print(f\"  - {file}\")\n",
    "    print(\"\\nProceeding with available files only.\")\n",
    "else:\n",
    "    print(\"\\nâœ… All required files are available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 26 model/dataset/metric combinations:\n",
      "  â€¢ ablangpdb_sabdab_cosine: AbLangPDB on sabdab using cosine\n",
      "  â€¢ ablangrbd_sabdab_cosine: AbLangRBD on sabdab using cosine\n",
      "  â€¢ ablangpre_sabdab_cosine: AbLangPre on sabdab using cosine\n",
      "  â€¢ ablang2_sabdab_cosine: AbLang2 on sabdab using cosine\n",
      "  â€¢ ablang_heavy_sabdab_cosine: AbLang-Heavy on sabdab using cosine\n",
      "  â€¢ antiberty_sabdab_cosine: AntiBERTy on sabdab using cosine\n",
      "  â€¢ balm_sabdab_cosine: BALM on sabdab using cosine\n",
      "  â€¢ esm2_sabdab_cosine: ESM-2 on sabdab using cosine\n",
      "  â€¢ igbert_sabdab_cosine: IgBERT on sabdab using cosine\n",
      "  â€¢ parapred_sabdab_cosine: Parapred on sabdab using cosine\n",
      "  â€¢ seqid_sabdab: SEQID on sabdab using seq_identity\n",
      "  â€¢ cdrh3id_sabdab: CDRH3ID on sabdab using cdrh3_identity\n",
      "  â€¢ ablangpdb_dms_cosine: AbLangPDB on dms using cosine\n",
      "  â€¢ ablangrbd_dms_cosine: AbLangRBD on dms using cosine\n",
      "  â€¢ ablangpre_dms_cosine: AbLangPre on dms using cosine\n",
      "  â€¢ ablang2_dms_cosine: AbLang2 on dms using cosine\n",
      "  â€¢ ablang_heavy_dms_cosine: AbLang-Heavy on dms using cosine\n",
      "  â€¢ antiberty_dms_cosine: AntiBERTy on dms using cosine\n",
      "  â€¢ balm_dms_cosine: BALM on dms using cosine\n",
      "  â€¢ esm2_dms_cosine: ESM-2 on dms using cosine\n",
      "  â€¢ igbert_dms_cosine: IgBERT on dms using cosine\n",
      "  â€¢ parapred_dms_cosine: Parapred on dms using cosine\n",
      "  â€¢ seqid_dms: SEQID on dms using seq_identity\n",
      "  â€¢ cdrh3id_dms: CDRH3ID on dms using cdrh3_identity\n",
      "  â€¢ abodybuilder2_sabdab_dtw: ABodyBuilder2_DTW_CDRs on sabdab using abodybuilder2_dtw_cdrs\n",
      "  â€¢ abodybuilder2_dms_dtw: ABodyBuilder2_DTW_CDRs on dms using abodybuilder2_dtw_cdrs\n"
     ]
    }
   ],
   "source": [
    "# Complete configuration for all model/dataset/metric combinations\n",
    "CONFIGS = {\n",
    "    # SAbDab Dataset Configurations\n",
    "    \"ablangpdb_sabdab_cosine\": {\n",
    "        \"df_path\": \"ablangpdb_renameddatasets.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLangPDB\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"ablangrbd_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_ablangrbd.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLangRBD\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"ablangpre_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_ablangpre.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLangPre\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"ablang2_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_ablang2.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLang2\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"ablang_heavy_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_ablang-heavy.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLang-Heavy\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"antiberty_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_antiberty.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AntiBERTy\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"balm_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_balm.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"BALM\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"esm2_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_esm-2.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"ESM-2\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"igbert_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_igbert.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"IgBERT\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"parapred_sabdab_cosine\": {\n",
    "        \"df_path\": \"sabdab_embeddedby_parapred.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"Parapred\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"seqid_sabdab\": {\n",
    "        \"df_path\": \"ablangpdb_renameddatasets.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"SEQID\",\n",
    "        \"score_type\": \"seq_identity\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \"cdrh3id_sabdab\": {\n",
    "        \"df_path\": \"ablangpdb_renameddatasets.parquet\",\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"CDRH3ID\",\n",
    "        \"score_type\": \"cdrh3_identity\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\"\n",
    "    },\n",
    "    \n",
    "    # DMS Dataset Configurations\n",
    "    \"ablangpdb_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_ablangpdb.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLangPDB\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"ablangrbd_dms_cosine\": {\n",
    "        \"df_path\": \"ablangrbd_renameddatasets.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLangRBD\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"ablangpre_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_ablangpre.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLangPre\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"ablang2_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_ablang2.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLang2\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"ablang_heavy_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_ablang-heavy.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AbLang-Heavy\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"antiberty_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_antiberty.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"AntiBERTy\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"balm_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_balm.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"BALM\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"esm2_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_esm-2.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"ESM-2\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"igbert_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_igbert.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"IgBERT\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"parapred_dms_cosine\": {\n",
    "        \"df_path\": \"dms_embeddedby_parapred.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"Parapred\",\n",
    "        \"score_type\": \"cosine\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"seqid_dms\": {\n",
    "        \"df_path\": \"ablangrbd_renameddatasets.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"SEQID\",\n",
    "        \"score_type\": \"seq_identity\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \"cdrh3id_dms\": {\n",
    "        \"df_path\": \"ablangrbd_renameddatasets.parquet\",\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"CDRH3ID\",\n",
    "        \"score_type\": \"cdrh3_identity\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\"\n",
    "    },\n",
    "    \n",
    "    # ABodyBuilder2 DTW CDRs Configurations\n",
    "    \"abodybuilder2_sabdab_dtw\": {\n",
    "        \"df_path\": \"ablangpdb_renameddatasets.parquet\",  # Not used for this score_type, but required for function signature\n",
    "        \"labels_val\": \"ablangpdb_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"ablangpdb_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"ABodyBuilder2_DTW_CDRs\",\n",
    "        \"score_type\": \"abodybuilder2_dtw_cdrs\",\n",
    "        \"function\": calculate_metrics.get_metrics,\n",
    "        \"dataset_type\": \"sabdab\",\n",
    "        \"matrix_file_val\": \"sabdab_pairwise_cdr_sims_train_vs_val.npy\",\n",
    "        \"matrix_file_test\": \"sabdab_pairwise_cdr_sims_train_vs_test.npy\"\n",
    "    },\n",
    "    \"abodybuilder2_dms_dtw\": {\n",
    "        \"df_path\": \"ablangrbd_renameddatasets.parquet\",  # Not used for this score_type, but required for function signature\n",
    "        \"labels_val\": \"dms_train_val_label_mat.pt\",\n",
    "        \"labels_test\": \"dms_train_test_label_mat.pt\",\n",
    "        \"model_name\": \"ABodyBuilder2_DTW_CDRs\",\n",
    "        \"score_type\": \"abodybuilder2_dtw_cdrs\",\n",
    "        \"function\": calculate_metrics_dms.get_metrics_dms,\n",
    "        \"dataset_type\": \"dms\",\n",
    "        \"matrix_file_val\": \"dms_pairwise_cdr_sims_train_vs_val.npy\",\n",
    "        \"matrix_file_test\": \"dms_pairwise_cdr_sims_train_vs_test.npy\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(CONFIGS)} model/dataset/metric combinations:\")\n",
    "for name, config in CONFIGS.items():\n",
    "    print(f\"  â€¢ {name}: {config['model_name']} on {config['dataset_type']} using {config['score_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Available Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ablangpdb_sabdab_cosine: Ready to run\n",
      "âœ… ablangrbd_sabdab_cosine: Ready to run\n",
      "âœ… ablangpre_sabdab_cosine: Ready to run\n",
      "âœ… ablang2_sabdab_cosine: Ready to run\n",
      "âœ… ablang_heavy_sabdab_cosine: Ready to run\n",
      "âœ… antiberty_sabdab_cosine: Ready to run\n",
      "âœ… balm_sabdab_cosine: Ready to run\n",
      "âœ… esm2_sabdab_cosine: Ready to run\n",
      "âœ… igbert_sabdab_cosine: Ready to run\n",
      "âœ… parapred_sabdab_cosine: Ready to run\n",
      "âœ… seqid_sabdab: Ready to run\n",
      "âœ… cdrh3id_sabdab: Ready to run\n",
      "âœ… ablangpdb_dms_cosine: Ready to run\n",
      "âœ… ablangrbd_dms_cosine: Ready to run\n",
      "âœ… ablangpre_dms_cosine: Ready to run\n",
      "âœ… ablang2_dms_cosine: Ready to run\n",
      "âœ… ablang_heavy_dms_cosine: Ready to run\n",
      "âœ… antiberty_dms_cosine: Ready to run\n",
      "âœ… balm_dms_cosine: Ready to run\n",
      "âœ… esm2_dms_cosine: Ready to run\n",
      "âœ… igbert_dms_cosine: Ready to run\n",
      "âœ… parapred_dms_cosine: Ready to run\n",
      "âœ… seqid_dms: Ready to run\n",
      "âœ… cdrh3id_dms: Ready to run\n",
      "âœ… abodybuilder2_sabdab_dtw: Ready to run\n",
      "âœ… abodybuilder2_dms_dtw: Ready to run\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "  â€¢ Available configurations: 26/26\n",
      "  â€¢ Missing configurations: 0\n"
     ]
    }
   ],
   "source": [
    "# Check which configurations can actually run based on available files\n",
    "available_configs = {}\n",
    "missing_configs = []\n",
    "\n",
    "for config_name, config in CONFIGS.items():\n",
    "    files_to_check = [config[\"df_path\"], config[\"labels_val\"], config[\"labels_test\"]]\n",
    "    missing_files = [f for f in files_to_check if not os.path.exists(f)]\n",
    "    \n",
    "    if not missing_files:\n",
    "        available_configs[config_name] = config\n",
    "        print(f\"âœ… {config_name}: Ready to run\")\n",
    "    else:\n",
    "        missing_configs.append(config_name)\n",
    "        print(f\"âŒ {config_name}: Missing files - {missing_files}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Summary:\")\n",
    "print(f\"  â€¢ Available configurations: {len(available_configs)}/{len(CONFIGS)}\")\n",
    "print(f\"  â€¢ Missing configurations: {len(missing_configs)}\")\n",
    "\n",
    "if missing_configs:\n",
    "    print(f\"\\nâš ï¸ Configurations that will be skipped: {', '.join(missing_configs)}\")\n",
    "\n",
    "if not available_configs:\n",
    "    raise RuntimeError(\"âŒ No configurations are available to run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Pre-computed Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using precomputed thresholds for 24 configurations\n",
      "  â€¢ ablangpdb_sabdab_cosine: {'epitope_threshold': 0.5037, 'antigen_threshold': 0.2697}\n",
      "  â€¢ ablangrbd_sabdab_cosine: {'epitope_threshold': 0.7912, 'antigen_threshold': -0.2969}\n",
      "  â€¢ ablangpre_sabdab_cosine: {'epitope_threshold': 0.6941, 'antigen_threshold': 0.5851}\n",
      "  â€¢ parapred_sabdab_cosine: {'epitope_threshold': 0.9985, 'antigen_threshold': 0.9974}\n",
      "  â€¢ seqid_sabdab: {'epitope_threshold': 0.6684, 'antigen_threshold': 0.338}\n",
      "  â€¢ cdrh3id_sabdab: {'epitope_threshold': 0.2727, 'antigen_threshold': 0.0}\n",
      "  â€¢ ablangpdb_dms_cosine: {'epitope_threshold': -0.0419}\n",
      "  â€¢ ablangrbd_dms_cosine: {'epitope_threshold': 0.8493}\n",
      "  â€¢ ablangpre_dms_cosine: {'epitope_threshold': 0.6608}\n",
      "  â€¢ parapred_dms_cosine: {'epitope_threshold': 0.9888}\n",
      "  â€¢ seqid_dms: {'epitope_threshold': 0.6497}\n",
      "  â€¢ cdrh3id_dms: {'epitope_threshold': 0.1905}\n",
      "  â€¢ ablang2_sabdab_cosine: {'epitope_threshold': 0.9325, 'antigen_threshold': 0.8962}\n",
      "  â€¢ ablang_heavy_sabdab_cosine: {'epitope_threshold': 0.7814, 'antigen_threshold': 0.6215}\n",
      "  â€¢ antiberty_sabdab_cosine: {'epitope_threshold': 0.8272, 'antigen_threshold': 0.6691}\n",
      "  â€¢ balm_sabdab_cosine: {'epitope_threshold': 0.942, 'antigen_threshold': 0.92}\n",
      "  â€¢ esm2_sabdab_cosine: {'epitope_threshold': 0.9923, 'antigen_threshold': 0.9866}\n",
      "  â€¢ igbert_sabdab_cosine: {'epitope_threshold': 0.9721, 'antigen_threshold': 0.9596}\n",
      "  â€¢ ablang2_dms_cosine: {'epitope_threshold': 0.5205}\n",
      "  â€¢ ablang_heavy_dms_cosine: {'epitope_threshold': 0.6617}\n",
      "  â€¢ antiberty_dms_cosine: {'epitope_threshold': 0.6673}\n",
      "  â€¢ balm_dms_cosine: {'epitope_threshold': 0.9378}\n",
      "  â€¢ esm2_dms_cosine: {'epitope_threshold': 0.993}\n",
      "  â€¢ igbert_dms_cosine: {'epitope_threshold': 0.9314}\n"
     ]
    }
   ],
   "source": [
    "# Optional: Pre-computed thresholds to skip threshold optimization\n",
    "# Uncomment and set values to reuse previous results for faster execution\n",
    "\n",
    "PRECOMPUTED_THRESHOLDS = {\n",
    "    # Existing pre-computed thresholds (keep these values)\n",
    "    \"ablangpdb_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.5037,\n",
    "        \"antigen_threshold\": 0.2697\n",
    "    },\n",
    "    \"ablangrbd_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.7912,\n",
    "        \"antigen_threshold\": -0.2969\n",
    "    },\n",
    "    \"ablangpre_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.6941,\n",
    "        \"antigen_threshold\": 0.5851\n",
    "    },\n",
    "    \"parapred_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.9985,\n",
    "        \"antigen_threshold\": 0.9974\n",
    "    },\n",
    "    \"seqid_sabdab\": {\n",
    "        \"epitope_threshold\": 0.6684,\n",
    "        \"antigen_threshold\": 0.3380\n",
    "    },\n",
    "    \"cdrh3id_sabdab\": {\n",
    "        \"epitope_threshold\": 0.2727,\n",
    "        \"antigen_threshold\": 0.0000\n",
    "    },\n",
    "    \"ablangpdb_dms_cosine\": {\n",
    "        \"epitope_threshold\": -0.0419\n",
    "    },\n",
    "    \"ablangrbd_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.8493\n",
    "    },\n",
    "    \"ablangpre_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.6608\n",
    "    },\n",
    "    \"parapred_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.9888\n",
    "    },\n",
    "    \"seqid_dms\": {\n",
    "        \"epitope_threshold\": 0.6497\n",
    "    },\n",
    "    \"cdrh3id_dms\": {\n",
    "        \"epitope_threshold\": 0.1905\n",
    "    },\n",
    "\n",
    "    \"ablang2_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.9325,\n",
    "        \"antigen_threshold\": 0.8962\n",
    "    },\n",
    "    \"ablang_heavy_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.7814,\n",
    "        \"antigen_threshold\": 0.6215\n",
    "    },\n",
    "    \"antiberty_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.8272,\n",
    "        \"antigen_threshold\": 0.6691\n",
    "    },\n",
    "    \"balm_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.9420,\n",
    "        \"antigen_threshold\": 0.9200\n",
    "    },\n",
    "    \"esm2_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.9923,\n",
    "        \"antigen_threshold\": 0.9866\n",
    "    },\n",
    "    \"igbert_sabdab_cosine\": {\n",
    "        \"epitope_threshold\": 0.9721,\n",
    "        \"antigen_threshold\": 0.9596\n",
    "    },\n",
    "    \"ablang2_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.5205\n",
    "    },\n",
    "    \"ablang_heavy_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.6617\n",
    "    },\n",
    "    \"antiberty_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.6673\n",
    "    },\n",
    "    \"balm_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.9378\n",
    "    },\n",
    "    \"esm2_dms_cosine\": {\n",
    "        \"epitope_threshold\": .9930\n",
    "    },\n",
    "    \"igbert_dms_cosine\": {\n",
    "        \"epitope_threshold\": 0.9314\n",
    "    },\n",
    "    \n",
    "    \"abodybuilder2_dms_dtw\": {\n",
    "        \"epitope_threshold\": 0.2496\n",
    "    },\n",
    "    \"abodybuilder2_sabdab_dtw\": {\n",
    "        \"epitope_threshold\": 0.0148,\n",
    "        \"antigen_threshold\": 0.0000\n",
    "    },\n",
    "}\n",
    "\n",
    "use_precomputed = len(PRECOMPUTED_THRESHOLDS) > 0\n",
    "if use_precomputed:\n",
    "    print(f\"ðŸ”„ Using precomputed thresholds for {len(PRECOMPUTED_THRESHOLDS)} configurations\")\n",
    "    for config_name, thresholds in PRECOMPUTED_THRESHOLDS.items():\n",
    "        print(f\"  â€¢ {config_name}: {thresholds}\")\n",
    "else:\n",
    "    print(\"ðŸ†• Computing fresh thresholds for all configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Comprehensive Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE BENCHMARK EXECUTION\n",
      "======================================================================\n",
      "Total configurations to run: 26\n",
      "Recalculate summary metrics: False\n",
      "\n",
      "======================================================================\n",
      "[1/26] Running: ablangpdb_sabdab_cosine\n",
      "Model: AbLangPDB, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for AbLangPDB on sabdab:\n",
      "\n",
      "--- Epitope-level performance ---\n",
      "Model: AbLangPDB\n",
      "Dataset: sabdab_ep\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.809048\n",
      "Average_Precision: 0.541921\n",
      "F1_Score: 0.556708\n",
      "Threshold: 0.503700\n",
      "\n",
      "--- Antigen-level performance ---\n",
      "Model: AbLangPDB\n",
      "Dataset: sabdab_ag\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.788735\n",
      "Average_Precision: 0.508352\n",
      "F1_Score: 0.504352\n",
      "Threshold: 0.269700\n",
      "\n",
      "âœ… [1/26] ablangpdb_sabdab_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[2/26] Running: ablangrbd_sabdab_cosine\n",
      "Model: AbLangRBD, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for AbLangRBD on sabdab:\n",
      "\n",
      "--- Epitope-level performance ---\n",
      "Model: AbLangRBD\n",
      "Dataset: sabdab_ep\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.575304\n",
      "Average_Precision: 0.160117\n",
      "F1_Score: 0.144746\n",
      "Threshold: 0.791200\n",
      "\n",
      "--- Antigen-level performance ---\n",
      "Model: AbLangRBD\n",
      "Dataset: sabdab_ag\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.509033\n",
      "Average_Precision: 0.153709\n",
      "F1_Score: 0.185259\n",
      "Threshold: -0.296900\n",
      "\n",
      "âœ… [2/26] ablangrbd_sabdab_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[3/26] Running: ablangpre_sabdab_cosine\n",
      "Model: AbLangPre, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for AbLangPre on sabdab:\n",
      "\n",
      "--- Epitope-level performance ---\n",
      "Model: AbLangPre\n",
      "Dataset: sabdab_ep\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.631829\n",
      "Average_Precision: 0.076850\n",
      "F1_Score: 0.129045\n",
      "Threshold: 0.694100\n",
      "\n",
      "--- Antigen-level performance ---\n",
      "Model: AbLangPre\n",
      "Dataset: sabdab_ag\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.594305\n",
      "Average_Precision: 0.150513\n",
      "F1_Score: 0.209655\n",
      "Threshold: 0.585100\n",
      "\n",
      "âœ… [3/26] ablangpre_sabdab_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[4/26] Running: ablang2_sabdab_cosine\n",
      "Model: AbLang2, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "Using provided Epitope threshold: 0.9325\n",
      "Using provided Antigen threshold: 0.8962\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Positive label >= 0.5) ---\n",
      "ROC-AUC: 0.5403, Average Precision: 0.0466, F1 Score: 0.0818\n",
      "\n",
      "--- Analyzing Antigen-level performance on TEST data (Positive label >= 0.2) ---\n",
      "ROC-AUC: 0.5364, Average Precision: 0.1220, F1 Score: 0.1881\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/AbLang2_sabdab_ep_summarymetrics.txt and output_csvs/AbLang2_sabdab_ag_summarymetrics.txt\n",
      "\n",
      "âœ… [4/26] ablang2_sabdab_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[5/26] Running: ablang_heavy_sabdab_cosine\n",
      "Model: AbLang-Heavy, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "Using provided Epitope threshold: 0.7814\n",
      "Using provided Antigen threshold: 0.6215\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Positive label >= 0.5) ---\n",
      "ROC-AUC: 0.6504, Average Precision: 0.0970, F1 Score: 0.1440\n",
      "\n",
      "--- Analyzing Antigen-level performance on TEST data (Positive label >= 0.2) ---\n",
      "ROC-AUC: 0.6225, Average Precision: 0.1751, F1 Score: 0.2262\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/AbLang-Heavy_sabdab_ep_summarymetrics.txt and output_csvs/AbLang-Heavy_sabdab_ag_summarymetrics.txt\n",
      "\n",
      "âœ… [5/26] ablang_heavy_sabdab_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[6/26] Running: antiberty_sabdab_cosine\n",
      "Model: AntiBERTy, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "Using provided Epitope threshold: 0.8272\n",
      "Using provided Antigen threshold: 0.6691\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Positive label >= 0.5) ---\n",
      "ROC-AUC: 0.6587, Average Precision: 0.1210, F1 Score: 0.1716\n",
      "\n",
      "--- Analyzing Antigen-level performance on TEST data (Positive label >= 0.2) ---\n",
      "ROC-AUC: 0.6372, Average Precision: 0.1887, F1 Score: 0.2362\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/AntiBERTy_sabdab_ep_summarymetrics.txt and output_csvs/AntiBERTy_sabdab_ag_summarymetrics.txt\n",
      "\n",
      "âœ… [6/26] antiberty_sabdab_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[7/26] Running: balm_sabdab_cosine\n",
      "Model: BALM, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "Using provided Epitope threshold: 0.9420\n",
      "Using provided Antigen threshold: 0.9200\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Positive label >= 0.5) ---\n",
      "ROC-AUC: 0.6121, Average Precision: 0.0686, F1 Score: 0.1198\n",
      "\n",
      "--- Analyzing Antigen-level performance on TEST data (Positive label >= 0.2) ---\n",
      "ROC-AUC: 0.5909, Average Precision: 0.1513, F1 Score: 0.2194\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/BALM_sabdab_ep_summarymetrics.txt and output_csvs/BALM_sabdab_ag_summarymetrics.txt\n",
      "\n",
      "âœ… [7/26] balm_sabdab_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[8/26] Running: esm2_sabdab_cosine\n",
      "Model: ESM-2, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "Using provided Epitope threshold: 0.9923\n",
      "Using provided Antigen threshold: 0.9866\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Positive label >= 0.5) ---\n",
      "ROC-AUC: 0.5970, Average Precision: 0.0813, F1 Score: 0.0991\n",
      "\n",
      "--- Analyzing Antigen-level performance on TEST data (Positive label >= 0.2) ---\n",
      "ROC-AUC: 0.5539, Average Precision: 0.1332, F1 Score: 0.1919\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/ESM-2_sabdab_ep_summarymetrics.txt and output_csvs/ESM-2_sabdab_ag_summarymetrics.txt\n",
      "\n",
      "âœ… [8/26] esm2_sabdab_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[9/26] Running: igbert_sabdab_cosine\n",
      "Model: IgBERT, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "Using provided Epitope threshold: 0.9721\n",
      "Using provided Antigen threshold: 0.9596\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Positive label >= 0.5) ---\n",
      "ROC-AUC: 0.6020, Average Precision: 0.0670, F1 Score: 0.1176\n",
      "\n",
      "--- Analyzing Antigen-level performance on TEST data (Positive label >= 0.2) ---\n",
      "ROC-AUC: 0.5830, Average Precision: 0.1529, F1 Score: 0.2139\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/IgBERT_sabdab_ep_summarymetrics.txt and output_csvs/IgBERT_sabdab_ag_summarymetrics.txt\n",
      "\n",
      "âœ… [9/26] igbert_sabdab_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[10/26] Running: parapred_sabdab_cosine\n",
      "Model: Parapred, Dataset: sabdab, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for Parapred on sabdab:\n",
      "\n",
      "--- Epitope-level performance ---\n",
      "Model: Parapred\n",
      "Dataset: sabdab_ep\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.576177\n",
      "Average_Precision: 0.062524\n",
      "F1_Score: 0.095699\n",
      "Threshold: 0.998471\n",
      "\n",
      "--- Antigen-level performance ---\n",
      "Model: Parapred\n",
      "Dataset: sabdab_ag\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.538704\n",
      "Average_Precision: 0.121466\n",
      "F1_Score: 0.187072\n",
      "Threshold: 0.997420\n",
      "\n",
      "âœ… [10/26] parapred_sabdab_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[11/26] Running: seqid_sabdab\n",
      "Model: SEQID, Dataset: sabdab, Score: seq_identity\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for SEQID on sabdab:\n",
      "\n",
      "--- Epitope-level performance ---\n",
      "Model: SEQID\n",
      "Dataset: sabdab_ep\n",
      "Score_Type: seq_identity\n",
      "ROC_AUC: 0.610371\n",
      "Average_Precision: 0.093991\n",
      "F1_Score: 0.118971\n",
      "Threshold: 0.668400\n",
      "\n",
      "--- Antigen-level performance ---\n",
      "Model: SEQID\n",
      "Dataset: sabdab_ag\n",
      "Score_Type: seq_identity\n",
      "ROC_AUC: 0.544797\n",
      "Average_Precision: 0.140030\n",
      "F1_Score: 0.184720\n",
      "Threshold: 0.338000\n",
      "\n",
      "âœ… [11/26] seqid_sabdab loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[12/26] Running: cdrh3id_sabdab\n",
      "Model: CDRH3ID, Dataset: sabdab, Score: cdrh3_identity\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for CDRH3ID on sabdab:\n",
      "\n",
      "--- Epitope-level performance ---\n",
      "Model: CDRH3ID\n",
      "Dataset: sabdab_ep\n",
      "Score_Type: cdrh3_identity\n",
      "ROC_AUC: 0.564467\n",
      "Average_Precision: 0.074239\n",
      "F1_Score: 0.080056\n",
      "Threshold: 0.272700\n",
      "\n",
      "--- Antigen-level performance ---\n",
      "Model: CDRH3ID\n",
      "Dataset: sabdab_ag\n",
      "Score_Type: cdrh3_identity\n",
      "ROC_AUC: 0.527392\n",
      "Average_Precision: 0.123742\n",
      "F1_Score: 0.184847\n",
      "Threshold: 0.000000\n",
      "\n",
      "âœ… [12/26] cdrh3id_sabdab loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[13/26] Running: ablangpdb_dms_cosine\n",
      "Model: AbLangPDB, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for AbLangPDB on dms:\n",
      "\n",
      "--- Performance ---\n",
      "Model: AbLangPDB\n",
      "Dataset: dms\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.537878\n",
      "Average_Precision: 0.146938\n",
      "F1_Score: 0.204140\n",
      "Threshold: -0.041900\n",
      "\n",
      "âœ… [13/26] ablangpdb_dms_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[14/26] Running: ablangrbd_dms_cosine\n",
      "Model: AbLangRBD, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for AbLangRBD on dms:\n",
      "\n",
      "--- Performance ---\n",
      "Model: AbLangRBD\n",
      "Dataset: dms\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.844169\n",
      "Average_Precision: 0.640059\n",
      "F1_Score: 0.592582\n",
      "Threshold: 0.849300\n",
      "\n",
      "âœ… [14/26] ablangrbd_dms_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[15/26] Running: ablangpre_dms_cosine\n",
      "Model: AbLangPre, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for AbLangPre on dms:\n",
      "\n",
      "--- Performance ---\n",
      "Model: AbLangPre\n",
      "Dataset: dms\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.574838\n",
      "Average_Precision: 0.175561\n",
      "F1_Score: 0.214474\n",
      "Threshold: 0.660800\n",
      "\n",
      "âœ… [15/26] ablangpre_dms_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[16/26] Running: ablang2_dms_cosine\n",
      "Model: AbLang2, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Using provided F1 threshold: 0.5205 ---\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Binary epitope matching) ---\n",
      "ROC-AUC: 0.5371, Average Precision: 0.1289, F1 Score: 0.2027\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/AbLang2_dms_summarymetrics.txt\n",
      "\n",
      "âœ… [16/26] ablang2_dms_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[17/26] Running: ablang_heavy_dms_cosine\n",
      "Model: AbLang-Heavy, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Using provided F1 threshold: 0.6617 ---\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Binary epitope matching) ---\n",
      "ROC-AUC: 0.5611, Average Precision: 0.1563, F1 Score: 0.2096\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/AbLang-Heavy_dms_summarymetrics.txt\n",
      "\n",
      "âœ… [17/26] ablang_heavy_dms_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[18/26] Running: antiberty_dms_cosine\n",
      "Model: AntiBERTy, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Using provided F1 threshold: 0.6673 ---\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Binary epitope matching) ---\n",
      "ROC-AUC: 0.5726, Average Precision: 0.1666, F1 Score: 0.2133\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/AntiBERTy_dms_summarymetrics.txt\n",
      "\n",
      "âœ… [18/26] antiberty_dms_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[19/26] Running: balm_dms_cosine\n",
      "Model: BALM, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Using provided F1 threshold: 0.9378 ---\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Binary epitope matching) ---\n",
      "ROC-AUC: 0.5569, Average Precision: 0.1574, F1 Score: 0.2047\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/BALM_dms_summarymetrics.txt\n",
      "\n",
      "âœ… [19/26] balm_dms_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[20/26] Running: esm2_dms_cosine\n",
      "Model: ESM-2, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Using provided F1 threshold: 0.9930 ---\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Binary epitope matching) ---\n",
      "ROC-AUC: 0.5628, Average Precision: 0.1752, F1 Score: 0.2029\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/ESM-2_dms_summarymetrics.txt\n",
      "\n",
      "âœ… [20/26] esm2_dms_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[21/26] Running: igbert_dms_cosine\n",
      "Model: IgBERT, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Using provided F1 threshold: 0.9314 ---\n",
      "Preparing data with score_type: 'cosine' for TRAIN vs TEST...\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Binary epitope matching) ---\n",
      "ROC-AUC: 0.5388, Average Precision: 0.1394, F1 Score: 0.2036\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/IgBERT_dms_summarymetrics.txt\n",
      "\n",
      "âœ… [21/26] igbert_dms_cosine completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[22/26] Running: parapred_dms_cosine\n",
      "Model: Parapred, Dataset: dms, Score: cosine\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for Parapred on dms:\n",
      "\n",
      "--- Performance ---\n",
      "Model: Parapred\n",
      "Dataset: dms\n",
      "Score_Type: cosine\n",
      "ROC_AUC: 0.548983\n",
      "Average_Precision: 0.152483\n",
      "F1_Score: 0.201964\n",
      "Threshold: 0.988760\n",
      "\n",
      "âœ… [22/26] parapred_dms_cosine loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[23/26] Running: seqid_dms\n",
      "Model: SEQID, Dataset: dms, Score: seq_identity\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for SEQID on dms:\n",
      "\n",
      "--- Performance ---\n",
      "Model: SEQID\n",
      "Dataset: dms\n",
      "Score_Type: seq_identity\n",
      "ROC_AUC: 0.557926\n",
      "Average_Precision: 0.190401\n",
      "F1_Score: 0.208348\n",
      "Threshold: 0.649700\n",
      "\n",
      "âœ… [23/26] seqid_dms loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[24/26] Running: cdrh3id_dms\n",
      "Model: CDRH3ID, Dataset: dms, Score: cdrh3_identity\n",
      "======================================================================\n",
      "ðŸ“‹ Summary files already exist, skipping recalculation...\n",
      "\n",
      "ðŸ“Š Loading existing results for CDRH3ID on dms:\n",
      "\n",
      "--- Performance ---\n",
      "Model: CDRH3ID\n",
      "Dataset: dms\n",
      "Score_Type: cdrh3_identity\n",
      "ROC_AUC: 0.531481\n",
      "Average_Precision: 0.136912\n",
      "F1_Score: 0.202346\n",
      "Threshold: 0.190500\n",
      "\n",
      "âœ… [24/26] cdrh3id_dms loaded from existing files!\n",
      "\n",
      "======================================================================\n",
      "[25/26] Running: abodybuilder2_sabdab_dtw\n",
      "Model: ABodyBuilder2_DTW_CDRs, Dataset: sabdab, Score: abodybuilder2_dtw_cdrs\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Finding optimal F1 thresholds using VAL data ---\n",
      "Loading pre-computed similarity matrix from: sabdab_pairwise_cdr_sims_train_vs_val.npy\n",
      "Optimal F1 Threshold for Epitope (>=0.5): 0.0148\n",
      "Optimal F1 Threshold for Antigen (>=0.2): 0.0000\n",
      "Loading pre-computed similarity matrix from: sabdab_pairwise_cdr_sims_train_vs_test.npy\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Positive label >= 0.5) ---\n",
      "ROC-AUC: 0.5229, Average Precision: 0.0562, F1 Score: 0.0727\n",
      "\n",
      "--- Analyzing Antigen-level performance on TEST data (Positive label >= 0.2) ---\n",
      "ROC-AUC: 0.4804, Average Precision: 0.1030, F1 Score: 0.1848\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/ABodyBuilder2_DTW_CDRs_sabdab_ep_summarymetrics.txt and output_csvs/ABodyBuilder2_DTW_CDRs_sabdab_ag_summarymetrics.txt\n",
      "\n",
      "âœ… [25/26] abodybuilder2_sabdab_dtw completed successfully!\n",
      "\n",
      "======================================================================\n",
      "[26/26] Running: abodybuilder2_dms_dtw\n",
      "Model: ABodyBuilder2_DTW_CDRs, Dataset: dms, Score: abodybuilder2_dtw_cdrs\n",
      "======================================================================\n",
      "ðŸ“‹ Some summary files missing, proceeding with calculation...\n",
      "\n",
      "--- Finding optimal F1 threshold using VAL data ---\n",
      "Loading pre-computed similarity matrix from: dms_pairwise_cdr_sims_train_vs_val.npy\n",
      "Optimal F1 Threshold for Epitope matching: 0.2496\n",
      "Loading pre-computed similarity matrix from: dms_pairwise_cdr_sims_train_vs_test.npy\n",
      "\n",
      "--- Analyzing Epitope-level performance on TEST data (Binary epitope matching) ---\n",
      "ROC-AUC: 0.5533, Average Precision: 0.1611, F1 Score: 0.2005\n",
      "\n",
      "Results saved to output_csvs\n",
      "Summary metrics saved to output_csvs/ABodyBuilder2_DTW_CDRs_dms_summarymetrics.txt\n",
      "\n",
      "âœ… [26/26] abodybuilder2_dms_dtw completed successfully!\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE BENCHMARK EXECUTION SUMMARY\n",
      "======================================================================\n",
      "ablangpdb_sabdab_cosine        âœ… Loaded from existing files\n",
      "ablangrbd_sabdab_cosine        âœ… Loaded from existing files\n",
      "ablangpre_sabdab_cosine        âœ… Loaded from existing files\n",
      "ablang2_sabdab_cosine          âœ… Success\n",
      "ablang_heavy_sabdab_cosine     âœ… Success\n",
      "antiberty_sabdab_cosine        âœ… Success\n",
      "balm_sabdab_cosine             âœ… Success\n",
      "esm2_sabdab_cosine             âœ… Success\n",
      "igbert_sabdab_cosine           âœ… Success\n",
      "parapred_sabdab_cosine         âœ… Loaded from existing files\n",
      "seqid_sabdab                   âœ… Loaded from existing files\n",
      "cdrh3id_sabdab                 âœ… Loaded from existing files\n",
      "ablangpdb_dms_cosine           âœ… Loaded from existing files\n",
      "ablangrbd_dms_cosine           âœ… Loaded from existing files\n",
      "ablangpre_dms_cosine           âœ… Loaded from existing files\n",
      "ablang2_dms_cosine             âœ… Success\n",
      "ablang_heavy_dms_cosine        âœ… Success\n",
      "antiberty_dms_cosine           âœ… Success\n",
      "balm_dms_cosine                âœ… Success\n",
      "esm2_dms_cosine                âœ… Success\n",
      "igbert_dms_cosine              âœ… Success\n",
      "parapred_dms_cosine            âœ… Loaded from existing files\n",
      "seqid_dms                      âœ… Loaded from existing files\n",
      "cdrh3id_dms                    âœ… Loaded from existing files\n",
      "abodybuilder2_sabdab_dtw       âœ… Success\n",
      "abodybuilder2_dms_dtw          âœ… Success\n",
      "\n",
      "ðŸ“Š Results:\n",
      "  â€¢ Successful: 26/26\n",
      "  â€¢ Failed: 0\n",
      "\n",
      "ðŸŽ‰ All available configurations completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Execute all available configurations\n",
    "execution_results = {}\n",
    "failed_configs = []\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"COMPREHENSIVE BENCHMARK EXECUTION\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total configurations to run: {len(available_configs)}\")\n",
    "print(f\"Recalculate summary metrics: {RECALCULATE_SUMMARYMETRICS}\")\n",
    "\n",
    "for i, (config_name, config) in enumerate(available_configs.items(), 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"[{i}/{len(available_configs)}] Running: {config_name}\")\n",
    "    print(f\"Model: {config['model_name']}, Dataset: {config['dataset_type']}, Score: {config['score_type']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Check if summary files already exist and flag is False\n",
    "    if not RECALCULATE_SUMMARYMETRICS:\n",
    "        summary_files = get_summary_file_paths(config['model_name'], config['dataset_type'], OUTPUT_FOLDER)\n",
    "        all_summaries_exist = all(os.path.exists(f) for f in summary_files)\n",
    "        \n",
    "        if all_summaries_exist:\n",
    "            print(f\"ðŸ“‹ Summary files already exist, skipping recalculation...\")\n",
    "            read_and_display_summary_results(summary_files, config['model_name'], config['dataset_type'])\n",
    "            execution_results[config_name] = \"âœ… Loaded from existing files\"\n",
    "            print(f\"\\nâœ… [{i}/{len(available_configs)}] {config_name} loaded from existing files!\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"ðŸ“‹ Some summary files missing, proceeding with calculation...\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare arguments\n",
    "        args = {\n",
    "            \"df_path\": config[\"df_path\"],\n",
    "            \"labels_file_val\": config[\"labels_val\"],\n",
    "            \"labels_file_test\": config[\"labels_test\"],\n",
    "            \"score_type\": config[\"score_type\"],\n",
    "            \"model_name\": config[\"model_name\"],\n",
    "            \"output_folder\": OUTPUT_FOLDER\n",
    "        }\n",
    "        \n",
    "        # Add matrix file paths for ABodyBuilder2 DTW configurations\n",
    "        if config[\"score_type\"] == \"abodybuilder2_dtw_cdrs\":\n",
    "            args[\"matrix_file_val\"] = config[\"matrix_file_val\"]\n",
    "            args[\"matrix_file_test\"] = config[\"matrix_file_test\"]\n",
    "        \n",
    "        # Add precomputed thresholds if available\n",
    "        if config_name in PRECOMPUTED_THRESHOLDS:\n",
    "            thresholds = PRECOMPUTED_THRESHOLDS[config_name]\n",
    "            if config[\"dataset_type\"] == \"sabdab\":\n",
    "                if \"epitope_threshold\" in thresholds:\n",
    "                    args[\"epitope_threshold\"] = thresholds[\"epitope_threshold\"]\n",
    "                if \"antigen_threshold\" in thresholds:\n",
    "                    args[\"antigen_threshold\"] = thresholds[\"antigen_threshold\"]\n",
    "            elif config[\"dataset_type\"] == \"dms\":\n",
    "                if \"epitope_threshold\" in thresholds:\n",
    "                    args[\"epitope_threshold\"] = thresholds[\"epitope_threshold\"]\n",
    "        \n",
    "        # Execute the benchmark\n",
    "        config[\"function\"](**args)\n",
    "        \n",
    "        execution_results[config_name] = \"âœ… Success\"\n",
    "        print(f\"\\nâœ… [{i}/{len(available_configs)}] {config_name} completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ Error: {str(e)}\"\n",
    "        execution_results[config_name] = error_msg\n",
    "        failed_configs.append(config_name)\n",
    "        print(f\"\\nâŒ [{i}/{len(available_configs)}] {config_name} failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPREHENSIVE BENCHMARK EXECUTION SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for config_name, result in execution_results.items():\n",
    "    print(f\"{config_name:30} {result}\")\n",
    "\n",
    "successful_configs = len(available_configs) - len(failed_configs)\n",
    "print(f\"\\nðŸ“Š Results:\")\n",
    "print(f\"  â€¢ Successful: {successful_configs}/{len(available_configs)}\")\n",
    "print(f\"  â€¢ Failed: {len(failed_configs)}\")\n",
    "\n",
    "if failed_configs:\n",
    "    print(f\"\\nâš ï¸ Failed configurations: {', '.join(failed_configs)}\")\n",
    "else:\n",
    "    print(\"\\nðŸŽ‰ All available configurations completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Comprehensive Excel Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Generating summary statistics...\n",
      "\n",
      "=== Summary Statistics ===\n",
      "Total summary files found: 39\n",
      "Unique models: 13 (ABodyBuilder2_DTW_CDRs, AbLang-Heavy, AbLang2, AbLangPDB, AbLangPre, AbLangRBD, AntiBERTy, BALM, CDRH3ID, ESM-2, IgBERT, Parapred, SEQID)\n",
      "Unique datasets: 3 (dms, sabdab_ag, sabdab_ep)\n",
      "Unique score types: 4 (abodybuilder2_dtw_cdrs, cdrh3_identity, cosine, seq_identity)\n",
      "Best ROC_AUC: AbLangRBD on dms (0.8442)\n",
      "Best Average_Precision: AbLangRBD on dms (0.6401)\n",
      "Best F1_Score: AbLangRBD on dms (0.5926)\n",
      "\n",
      "======================================================================\n",
      "GENERATING COMPREHENSIVE EXCEL REPORT\n",
      "======================================================================\n",
      "Collecting summary metrics from output_csvs...\n",
      "Found 39 summary files\n",
      "Creating pivot table...\n",
      "Pivot table created with 13 models and 9 metric columns\n",
      "Ranking values for formatting...\n",
      "Exporting to Excel: output_csvs/comprehensive_benchmarking_results.xlsx\n",
      "âœ… Excel file generated successfully: output_csvs/comprehensive_benchmarking_results.xlsx\n",
      "\n",
      "ðŸŽ‰ Comprehensive Excel report generated successfully!\n",
      "ðŸ“ File location: output_csvs/comprehensive_benchmarking_results.xlsx\n",
      "ðŸ“ File size: 5,977 bytes\n",
      "\n",
      "ðŸ“– Excel Report Contents:\n",
      "  â€¢ Models as rows (AbLangPDB, AbLangRBD, AbLangPre, SEQID, CDRH3ID)\n",
      "  â€¢ Datasets grouped as column headers (SAbDab, DMS)\n",
      "  â€¢ Metrics: ROC-AUC, Average Precision, F1 Score\n",
      "  â€¢ Best performance: Bold formatting\n",
      "  â€¢ Second best: Italic formatting\n",
      "  â€¢ Values rounded to 4 decimal places\n"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics\n",
    "print(\"\\nðŸ“Š Generating summary statistics...\")\n",
    "print_summary_stats(OUTPUT_FOLDER)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING COMPREHENSIVE EXCEL REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Generate the Excel file\n",
    "    excel_path = generate_results_excel(\n",
    "        output_folder=OUTPUT_FOLDER,\n",
    "        excel_filename=EXCEL_FILENAME\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Comprehensive Excel report generated successfully!\")\n",
    "    print(f\"ðŸ“ File location: {excel_path}\")\n",
    "    print(f\"ðŸ“ File size: {os.path.getsize(excel_path):,} bytes\")\n",
    "    \n",
    "    # Provide usage instructions\n",
    "    print(f\"\\nðŸ“– Excel Report Contents:\")\n",
    "    print(f\"  â€¢ Models as rows (AbLangPDB, AbLangRBD, AbLangPre, SEQID, CDRH3ID)\")\n",
    "    print(f\"  â€¢ Datasets grouped as column headers (SAbDab, DMS)\")\n",
    "    print(f\"  â€¢ Metrics: ROC-AUC, Average Precision, F1 Score\")\n",
    "    print(f\"  â€¢ Best performance: Bold formatting\")\n",
    "    print(f\"  â€¢ Second best: Italic formatting\")\n",
    "    print(f\"  â€¢ Values rounded to 4 decimal places\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error generating Excel report: {str(e)}\")\n",
    "    print(\"\\nDebugging information:\")\n",
    "    print(f\"  â€¢ Output folder: {OUTPUT_FOLDER}\")\n",
    "    print(f\"  â€¢ Files in folder: {len(os.listdir(OUTPUT_FOLDER))}\")\n",
    "    \n",
    "    # List summary files found\n",
    "    import glob\n",
    "    summary_files = glob.glob(os.path.join(OUTPUT_FOLDER, \"*summarymetrics.txt\"))\n",
    "    print(f\"  â€¢ Summary files found: {len(summary_files)}\")\n",
    "    for f in summary_files[:5]:  # Show first 5\n",
    "        print(f\"    - {os.path.basename(f)}\")\n",
    "    if len(summary_files) > 5:\n",
    "        print(f\"    - ... and {len(summary_files)-5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE PIPELINE COMPLETION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ”§ Configuration:\n",
      "  â€¢ Recalculated embeddings: False\n",
      "  â€¢ Used precomputed thresholds: True\n",
      "  â€¢ Batch size: 256\n",
      "\n",
      "ðŸ“ˆ Benchmarking Results:\n",
      "  â€¢ Total configurations possible: 26\n",
      "  â€¢ Configurations attempted: 26\n",
      "  â€¢ Successful runs: 26\n",
      "  â€¢ Failed runs: 0\n",
      "\n",
      "ðŸ“Š Excel Report:\n",
      "  â€¢ Status: âœ… Generated successfully\n",
      "  â€¢ Location: output_csvs/comprehensive_benchmarking_results.xlsx\n",
      "  â€¢ Ready for analysis and sharing\n",
      "\n",
      "ðŸ”¬ Models Configured for Benchmarking:\n",
      "  â€¢ ABodyBuilder2_DTW_CDRs (abodybuilder2_dtw_cdrs)\n",
      "  â€¢ AbLang-Heavy (cosine)\n",
      "  â€¢ AbLang2 (cosine)\n",
      "  â€¢ AbLangPDB (cosine)\n",
      "  â€¢ AbLangPre (cosine)\n",
      "  â€¢ AbLangRBD (cosine)\n",
      "  â€¢ AntiBERTy (cosine)\n",
      "  â€¢ BALM (cosine)\n",
      "  â€¢ CDRH3ID (cdrh3_identity)\n",
      "  â€¢ ESM-2 (cosine)\n",
      "  â€¢ IgBERT (cosine)\n",
      "  â€¢ Parapred (cosine)\n",
      "  â€¢ SEQID (seq_identity)\n",
      "\n",
      "ðŸ“Š Datasets Configured:\n",
      "  â€¢ DMS\n",
      "  â€¢ SABDAB\n",
      "\n",
      "ðŸŽ¯ Next Steps:\n",
      "  1. ðŸ“Š Open the Excel report for comprehensive performance comparison\n",
      "  2. ðŸ” Identify best-performing models for each dataset\n",
      "  3. ðŸ“ˆ Analyze performance patterns across different similarity metrics\n",
      "  4. ðŸ“‹ Share results with your research team\n",
      "  5. ðŸ“ Consider additional analyses based on findings\n",
      "\n",
      "ðŸ’¡ Model Coverage Summary:\n",
      "  â€¢ Total unique models: 13\n",
      "  â€¢ Embedding-based models: AbLangPDB, AbLangRBD, AbLangPre, AbLang2,\n",
      "    AbLang-Heavy, AntiBERTy, BALM, ESM-2, IgBERT, Parapred\n",
      "  â€¢ Sequence-based models: SEQID, CDRH3ID\n",
      "  â€¢ Total configurations: 26\n",
      "\n",
      "ðŸ Comprehensive benchmarking pipeline completed!\n",
      "\n",
      "ðŸ“„ Report: output_csvs/comprehensive_benchmarking_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE PIPELINE COMPLETION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ”§ Configuration:\")\n",
    "print(f\"  â€¢ Recalculated embeddings: {RECALCULATE_EMBEDDINGS}\")\n",
    "print(f\"  â€¢ Used precomputed thresholds: {use_precomputed}\")\n",
    "print(f\"  â€¢ Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Benchmarking Results:\")\n",
    "print(f\"  â€¢ Total configurations possible: {len(CONFIGS)}\")\n",
    "print(f\"  â€¢ Configurations attempted: {len(available_configs)}\")\n",
    "print(f\"  â€¢ Successful runs: {successful_configs}\")\n",
    "print(f\"  â€¢ Failed runs: {len(failed_configs)}\")\n",
    "\n",
    "if os.path.exists(os.path.join(OUTPUT_FOLDER, EXCEL_FILENAME)):\n",
    "    print(f\"\\nðŸ“Š Excel Report:\")\n",
    "    print(f\"  â€¢ Status: âœ… Generated successfully\")\n",
    "    print(f\"  â€¢ Location: {os.path.join(OUTPUT_FOLDER, EXCEL_FILENAME)}\")\n",
    "    print(f\"  â€¢ Ready for analysis and sharing\")\n",
    "else:\n",
    "    print(f\"\\nðŸ“Š Excel Report:\")\n",
    "    print(f\"  â€¢ Status: âŒ Generation failed\")\n",
    "    print(f\"  â€¢ Check error messages above\")\n",
    "\n",
    "print(f\"\\nðŸ”¬ Models Configured for Benchmarking:\")\n",
    "all_models = set()\n",
    "for config_name, config in CONFIGS.items():\n",
    "    all_models.add(f\"{config['model_name']} ({config['score_type']})\")\n",
    "        \n",
    "for model in sorted(all_models):\n",
    "    print(f\"  â€¢ {model}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Datasets Configured:\")\n",
    "datasets_configured = set()\n",
    "for config_name, config in CONFIGS.items():\n",
    "    datasets_configured.add(config['dataset_type'].upper())\n",
    "        \n",
    "for dataset in sorted(datasets_configured):\n",
    "    print(f\"  â€¢ {dataset}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Next Steps:\")\n",
    "print(f\"  1. ðŸ“Š Open the Excel report for comprehensive performance comparison\")\n",
    "print(f\"  2. ðŸ” Identify best-performing models for each dataset\")\n",
    "print(f\"  3. ðŸ“ˆ Analyze performance patterns across different similarity metrics\")\n",
    "print(f\"  4. ðŸ“‹ Share results with your research team\")\n",
    "print(f\"  5. ðŸ“ Consider additional analyses based on findings\")\n",
    "\n",
    "if failed_configs:\n",
    "    print(f\"\\nâš ï¸ Failed Configurations to Investigate:\")\n",
    "    for config in failed_configs:\n",
    "        print(f\"  â€¢ {config}: {execution_results[config]}\")\n",
    "\n",
    "if missing_configs:\n",
    "    print(f\"\\nâ“ Configurations Not Attempted (Missing Files):\")\n",
    "    for config in missing_configs:\n",
    "        print(f\"  â€¢ {config}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Model Coverage Summary:\")\n",
    "print(f\"  â€¢ Total unique models: {len(all_models)}\")\n",
    "print(f\"  â€¢ Embedding-based models: AbLangPDB, AbLangRBD, AbLangPre, AbLang2,\")\n",
    "print(f\"    AbLang-Heavy, AntiBERTy, BALM, ESM-2, IgBERT, Parapred\")\n",
    "print(f\"  â€¢ Sequence-based models: SEQID, CDRH3ID\")\n",
    "print(f\"  â€¢ Total configurations: {len(CONFIGS)}\")\n",
    "\n",
    "print(f\"\\nðŸ Comprehensive benchmarking pipeline completed!\")\n",
    "print(f\"\\nðŸ“„ Report: {os.path.join(OUTPUT_FOLDER, EXCEL_FILENAME)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_clone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
